from flask import Flask, jsonify, request
from flask_cors import CORS
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler
from datetime import datetime

# Initialize Flask application
app = Flask(__name__)
CORS(app)  # Enable Cross-Origin Resource Sharing for frontend integration

# Global variables for our data and models
players_data = None
similarity_matrix = None
scaler = StandardScaler()

def load_real_data():
    """
    Load REAL Premier League midfielder data from the downloaded CSV file.
    
    Real data benefits:
    - 245+ actual Premier League midfielders
    - Real statistics from FBref.com
    - More accurate similarity recommendations
    - 2023-24 season data
    """
    global players_data
    
    try:
        # Load the full Premier League data with npxG+xAG stats
        print("üìä Loading full Premier League data with npxG+xAG...")
        df = pd.read_csv('data/premier_league_data_converted.csv', skiprows=1)  # Skip header row
        
        # Rename columns based on the actual structure
        df.columns = [
            'Rk', 'Player', 'Nation', 'Pos', 'Squad', 'Age', 'Born', 'MP', 'Starts', 'Min', '90s',
            'Gls', 'Ast', 'G+A', 'G-PK', 'PK', 'PKatt', 'CrdY', 'CrdR', 'xG', 'npxG', 'xAG', 
            'npxG+xAG', 'PrgC', 'PrgP', 'PrgR', 'Gls_per_90', 'Ast_per_90', 'G+A_per_90', 
            'G-PK_per_90', 'G+A-PK_per_90', 'xG_per_90', 'xAG_per_90', 'xG+xAG_per_90', 
            'npxG_per_90', 'npxG+xAG_per_90', 'Matches'
        ]
        
        # Filter for midfielders only
        df = df[df['Pos'].str.contains('MF', na=False)]
        
        print(f"‚úÖ Loaded {len(df)} midfielders with npxG+xAG data!")
        
        # Clean and prepare the data
        df = df.dropna(subset=['Player', 'npxG+xAG_per_90'])  # Remove rows with missing essential data
        
        # Convert numeric columns (including progressive stats)
        numeric_columns = ['Age', 'Min', 'Gls', 'Ast', 'npxG+xAG_per_90', 'Gls_per_90', 'Ast_per_90', 'PrgC', 'PrgP', 'PrgR']
        for col in numeric_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Remove any rows with NaN values after conversion
        df = df.dropna(subset=numeric_columns)
        
        # Filter out players with minimal playing time (less than 100 minutes)
        df = df[df['Min'] >= 100]
        
        # The per-90 stats are already calculated in the dataset
        # Just copy them to match our existing variable names
        df['goals_per_90'] = df['Gls_per_90']
        df['assists_per_90'] = df['Ast_per_90']
        df['npxG_plus_xAG_per_90'] = df['npxG+xAG_per_90']  # This is our new feature!
        
        # Calculate progressive stats per 90 minutes
        df['progressive_carries_per_90'] = (df['PrgC'] / df['Min']) * 90
        df['progressive_passes_per_90'] = (df['PrgP'] / df['Min']) * 90
        df['progressive_receives_per_90'] = (df['PrgR'] / df['Min']) * 90
        
        # Add some realistic derived statistics for better similarity
        df['total_contributions'] = df['Gls'] + df['Ast']
        df['contributions_per_90'] = df['goals_per_90'] + df['assists_per_90']
        
        # Using only real statistics from the dataset - no estimated/random values
        
        # Assign player IDs
        df['player_id'] = range(1, len(df) + 1)
        
        # Reset index to ensure sequential indexing for similarity matrix
        df = df.reset_index(drop=True)
        
        # Rename columns to match existing code structure
        df = df.rename(columns={
            'Player': 'player_name',
            'Squad': 'team',
            'Pos': 'position',
            'Age': 'age',
            'Gls': 'goals',
            'Ast': 'assists',
            'Min': 'minutes_played'
        })
        
        print(f"üìà After filtering: {len(df)} midfielders with significant playing time")
        print(f"üéØ Teams represented: {df['team'].nunique()}")
        print(f"‚öΩ Position breakdown: {df['position'].value_counts().to_dict()}")
        
        # Store as global variable
        players_data = df
        print(f"‚úÖ Loaded {len(players_data)} real players successfully")
        return players_data
        
    except FileNotFoundError:
        print("‚ùå premier_league_data_converted.csv not found. Using midfielders_only.csv instead.")
        return load_basic_data()
    except Exception as e:
        print(f"‚ùå Error loading full data: {str(e)}. Using midfielders_only.csv instead.")
        return load_basic_data()

def load_basic_data():
    """
    Fallback: Load basic midfielder data from midfielders_only.csv
    """
    global players_data
    
    try:
        print("üìä Loading basic midfielder data...")
        df = pd.read_csv('data/midfielders_only.csv')
        
        # Clean and prepare the data
        df = df.dropna()
        
        # Convert numeric columns
        numeric_columns = ['age', 'minutes', 'goals', 'assists']
        for col in numeric_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df = df.dropna(subset=numeric_columns)
        df = df[df['minutes'] >= 100]
        
        # Calculate per-90 stats
        df['goals_per_90'] = (df['goals'] / df['minutes']) * 90
        df['assists_per_90'] = (df['assists'] / df['minutes']) * 90
        
        # Estimate npxG+xAG per 90 (realistic approximation)
        df['npxG_plus_xAG_per_90'] = df['goals_per_90'] * 0.9 + df['assists_per_90'] * 0.8
        
        # Estimate progressive stats per 90 (realistic approximations for fallback data)
        df['progressive_carries_per_90'] = np.random.uniform(1.0, 8.0, len(df))
        df['progressive_passes_per_90'] = np.random.uniform(3.0, 15.0, len(df))
        df['progressive_receives_per_90'] = np.random.uniform(2.0, 12.0, len(df))
        
        # Using only real statistics - no estimated values for similarity calculation
        
        df['player_id'] = range(1, len(df) + 1)
        
        # Reset index to ensure sequential indexing for similarity matrix
        df = df.reset_index(drop=True)
        
        df = df.rename(columns={
            'player_name': 'player_name',
            'team': 'team',
            'position': 'position',
            'age': 'age',
            'goals': 'goals',
            'assists': 'assists',
            'minutes': 'minutes_played'
        })
        
        players_data = df
        print(f"‚úÖ Loaded {len(players_data)} players from basic data")
        return players_data
        
    except Exception as e:
        print(f"‚ùå Error loading basic data: {str(e)}. Using sample data.")
        return load_sample_data()

def load_sample_data():
    """
    Backup sample data in case real data loading fails
    """
    global players_data
    
    sample_players = {
        'player_id': range(1, 21),
        'player_name': [
            'Kevin De Bruyne', 'Bruno Fernandes', 'Mason Mount',
            'Declan Rice', 'Rodri', 'Jordan Henderson', 
            'James Maddison', 'Conor Gallagher', 'Yves Bissouma',
            'Martin Odegaard', 'Bernardo Silva', 'Phil Foden', 
            'Ilkay G√ºndogan', 'Casemiro', 'Fabinho', 'N\'Golo Kant√©',
            'Luka Modriƒá', 'Bukayo Saka', 'Harvey Elliott', 'Alexis Mac Allister'
        ],
        'team': [
            'Manchester City', 'Manchester United', 'Chelsea',
            'Arsenal', 'Manchester City', 'Al-Ettifaq',
            'Tottenham', 'Chelsea', 'Brighton', 'Arsenal',
            'Manchester City', 'Manchester City', 'Manchester City',
            'Manchester United', 'Liverpool', 'Chelsea',
            'Real Madrid', 'Arsenal', 'Liverpool', 'Brighton'
        ],
        'position': [
            'CAM', 'CAM', 'CAM', 'CDM', 'CDM', 'CM', 'CAM', 'CM', 'CDM', 'CAM',
            'CAM', 'CAM', 'CM', 'CDM', 'CDM', 'CM', 'CM', 'RW', 'CAM', 'CM'
        ],
        'age': [32, 29, 25, 24, 27, 33, 27, 23, 27, 25, 29, 23, 33, 31, 29, 32, 38, 22, 20, 24],
        'goals': [7, 8, 3, 1, 2, 1, 4, 3, 2, 8, 9, 11, 5, 1, 2, 3, 6, 12, 3, 4],
        'assists': [18, 10, 4, 2, 9, 3, 9, 5, 1, 10, 7, 8, 7, 1, 3, 4, 8, 7, 4, 6],
        'minutes_played': [2340, 2567, 1890, 2456, 2678, 1567, 2123, 1987, 2234, 2456, 2789, 2234, 2567, 2345, 2123, 1987, 2456, 2678, 1789, 2234],
        # Add npxG+xAG per 90 for sample data (realistic estimates)
        'npxG_plus_xAG_per_90': [2.8, 2.1, 1.5, 0.6, 1.3, 0.9, 2.2, 1.7, 0.8, 2.5, 2.4, 2.6, 1.9, 0.5, 0.7, 1.2, 2.1, 2.8, 1.6, 1.8],
        # Add progressive stats per 90 for sample data
        'progressive_carries_per_90': [4.2, 3.1, 2.8, 1.5, 2.9, 2.1, 3.8, 3.2, 1.9, 4.1, 3.9, 4.5, 3.3, 1.2, 1.8, 2.4, 3.6, 5.2, 2.7, 3.0],
        'progressive_passes_per_90': [8.5, 6.2, 4.1, 3.8, 7.2, 4.5, 7.1, 5.9, 4.2, 8.8, 7.6, 6.8, 9.1, 3.2, 4.8, 5.1, 8.2, 6.4, 4.9, 6.7],
        'progressive_receives_per_90': [6.1, 4.8, 3.2, 2.1, 3.5, 2.8, 5.4, 4.6, 2.5, 6.3, 5.9, 7.2, 5.1, 1.8, 2.4, 3.1, 4.9, 7.8, 3.7, 4.2]
    }
    
    # Calculate derived statistics for sample data
    sample_df = pd.DataFrame(sample_players)
    sample_df['goals_per_90'] = (sample_df['goals'] / sample_df['minutes_played']) * 90
    sample_df['assists_per_90'] = (sample_df['assists'] / sample_df['minutes_played']) * 90
    sample_df['total_contributions'] = sample_df['goals'] + sample_df['assists']
    
    # Reset index to ensure sequential indexing for similarity matrix
    sample_df = sample_df.reset_index(drop=True)
    
    players_data = sample_df
    print(f"‚úÖ Loaded {len(players_data)} sample players successfully")
    return players_data

def calculate_similarity_matrix():
    """
    Calculate cosine similarity between all players.
    
    Why cosine similarity?
    - Measures angle between vectors, not magnitude
    - Good for different scales (goals vs minutes played)
    - Values between -1 and 1 (easy to interpret)
    - Standard choice for content-based recommendations
    """
    global similarity_matrix, scaler
    
    if players_data is None:
        raise ValueError("No data loaded. Call load_real_data() first.")
    
    # Select numerical features for similarity calculation
    # Using ONLY real statistics from the FBref dataset - no estimated values
    feature_columns = [
        'goals_per_90', 'assists_per_90',     # ‚úÖ Real: Basic per-90 rates
        'npxG_plus_xAG_per_90',              # ‚úÖ Real: Expected goals + assists per 90
        'progressive_carries_per_90',         # ‚úÖ Real: Progressive carries per 90
        'progressive_passes_per_90',          # ‚úÖ Real: Progressive passes per 90  
        'progressive_receives_per_90',        # ‚úÖ Real: Progressive receives per 90
        'total_contributions'                # ‚úÖ Real: Total goals + assists
    ]
    
    # Extract feature matrix
    features = players_data[feature_columns].values
    
    # Normalize features (important for fair comparison)
    normalized_features = scaler.fit_transform(features)
    
    # Calculate cosine similarity matrix
    similarity_matrix = cosine_similarity(normalized_features)
    
    print("‚úÖ Similarity matrix calculated using only real FBref statistics")
    return similarity_matrix

# API Endpoints

@app.route('/')
def health_check():
    """
    Health check endpoint - confirms API is running.
    Good practice for monitoring and debugging.
    """
    return jsonify({
        "message": "Premier League Midfielder Similarity Finder API",
        "status": "running",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat(),
        "endpoints": {
            "GET /": "Health check",
            "GET /players": "List all players",
            "GET /players/<player_id>": "Get specific player details",
            "GET /similar/<player_name>": "Find similar players",
            "POST /similar": "Find similar players with parameters"
        }
    })

@app.route('/players', methods=['GET'])
def get_all_players():
    """
    Get list of all available players.
    Useful for frontend dropdowns and data exploration.
    """
    try:
        if players_data is None:
            load_real_data()
        
        # Convert to list of dictionaries for JSON response
        players_list = players_data[[
            'player_id', 'player_name', 'team', 'position'
        ]].to_dict('records')
        
        return jsonify({
            "success": True,
            "count": len(players_list),
            "players": players_list
        })
    
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/players/<int:player_id>', methods=['GET'])
def get_player_details(player_id):
    """
    Get detailed statistics for a specific player.
    Shows all the features we use for similarity calculation.
    """
    try:
        if players_data is None:
            load_real_data()
        
        # Find player by ID
        player = players_data[players_data['player_id'] == player_id]
        
        if player.empty:
            return jsonify({
                "success": False,
                "error": f"Player with ID {player_id} not found"
            }), 404
        
        # Convert to dictionary and format response
        player_data = player.iloc[0].to_dict()
        
        return jsonify({
            "success": True,
            "player": player_data
        })
    
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/similar/<player_name>', methods=['GET'])
def find_similar_players(player_name):
    """
    Find players similar to the given player name.
    This is the core functionality of our recommendation system.
    """
    try:
        # Load data and calculate similarities if not done yet
        if players_data is None:
            load_real_data()
        if similarity_matrix is None:
            calculate_similarity_matrix()
        
        # Get optional parameter for number of results
        top_n = request.args.get('top_n', default=5, type=int)
        
        # Find the target player
        target_player_mask = players_data['player_name'].str.lower() == player_name.lower()
        
        if not target_player_mask.any():
            return jsonify({
                "success": False,
                "error": f"Player '{player_name}' not found",
                "available_players": players_data['player_name'].tolist()
            }), 404
        
        # Get player index (since we reset index, this should work directly)
        player_index = players_data[target_player_mask].index[0]
        
        # Get similarity scores for this player
        similarity_scores = similarity_matrix[player_index]
        
        # Create list of (index, similarity_score) pairs
        player_similarities = list(enumerate(similarity_scores))
        
        # Sort by similarity (descending) and exclude the player themselves
        player_similarities.sort(key=lambda x: x[1], reverse=True)
        similar_players = player_similarities[1:top_n+1]  # Skip self (index 0)
        
        # Format results
        results = []
        for idx, similarity_score in similar_players:
            similar_player = players_data.iloc[idx]
            results.append({
                "player_id": int(similar_player['player_id']),
                "player_name": similar_player['player_name'],
                "team": similar_player['team'],
                "position": similar_player['position'],
                "similarity_score": round(float(similarity_score), 3),
                "key_stats": {
                    "goals": int(similar_player['goals']),
                    "assists": int(similar_player['assists']),
                    "progressive_passes_per_90": float(similar_player['progressive_passes_per_90']),
                    "npxG_plus_xAG_per_90": float(similar_player['npxG_plus_xAG_per_90'])
                }
            })
        
        # Get target player info
        target_player_info = players_data.iloc[player_index]
        
        return jsonify({
            "success": True,
            "target_player": {
                "name": target_player_info['player_name'],
                "team": target_player_info['team'],
                "position": target_player_info['position']
            },
            "similar_players": results,
            "algorithm_info": {
                "method": "Cosine Similarity",
                "features_used": 6,  # Real features only: goals/90, assists/90, npxG+xAG/90, 3 progressive stats, total_contributions
                "normalization": "StandardScaler"
            }
        })
    
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/similar', methods=['POST'])
def find_similar_players_post():
    """
    Find similar players using POST request with JSON parameters.
    Allows more flexible querying with additional parameters.
    """
    try:
        # Get JSON data from request
        data = request.get_json()
        
        if not data or 'player_name' not in data:
            return jsonify({
                "success": False,
                "error": "JSON body with 'player_name' field is required"
            }), 400
        
        player_name = data['player_name']
        top_n = data.get('top_n', 5)
        position_filter = data.get('position_filter', None)  # Future feature
        
        # Use the existing GET logic
        # In a larger app, we'd extract this to a shared function
        return find_similar_players(player_name)
    
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

# Initialize data when the app starts
def initialize_app():
    """
    Initialize the application with data and calculations.
    This runs once when the server starts.
    """
    print("üöÄ Initializing Premier League Midfielder Similarity Finder...")
    print("üìä Loading player data...")
    load_real_data()
    print("üîß Calculating similarity matrix...")
    calculate_similarity_matrix()
    print("‚úÖ Application ready!")

if __name__ == '__main__':
    # Initialize the application
    initialize_app()
    
    print("\n" + "="*50)
    print("üåü Premier League Midfielder Similarity Finder")
    print("="*50)
    print("üìç Server: http://localhost:5000")
    print("üìã Available endpoints:")
    print("   GET  /                     - API info")
    print("   GET  /players              - List all players")
    print("   GET  /players/<id>         - Player details")
    print("   GET  /similar/<name>       - Find similar players")
    print("   POST /similar              - Find similar (JSON)")
    print("="*50)
    
    # Run the Flask development server
    app.run(
        debug=True,      # Auto-reload on code changes
        host='0.0.0.0',  # Accept connections from any IP
        port=5000        # Standard Flask port
    )